from fastapi import FastAPI
from pydantic import BaseModel
import tensorflow as tf
import pickle
import numpy as np
from tensorflow.keras.preprocessing.sequence import pad_sequences

# âœ… Initialize FastAPI app
app = FastAPI()

# âœ… Relative paths (WORKS inside Docker)
MODEL_PATH = "models/IT-Ticket-Prediction-Model-tuned.keras"
TOKENIZER_PATH = "models/tokenizer.pkl"

print("âœ… Loading model...")
model = tf.keras.models.load_model(MODEL_PATH)
print("âœ… Model loaded.")

print("âœ… Loading tokenizer...")
with open(TOKENIZER_PATH, "rb") as f:
    tokenizer = pickle.load(f)
print("âœ… Tokenizer loaded.")

# âœ… Define input format
class TicketRequest(BaseModel):
    text: str

# âœ… Root check endpoint
@app.get("/")
def read_root():
    return {"message": "âœ… Cloud IT Ticket Prediction API is live!"}

# âœ… Prediction endpoint with debug info
@app.post("/predict")
async def predict_ticket(request: TicketRequest):
    try:
        print("ðŸ”¹ Incoming request:", request)
        text = request.text
        print("ðŸ”¹ Extracted text:", text)

        # Tokenize
        sequence = tokenizer.texts_to_sequences([text])
        print("ðŸ”¹ Tokenized:", sequence)

        # Pad
        padded = pad_sequences(sequence, maxlen=50)
        print("ðŸ”¹ Padded:", padded)

        # Predict
        prediction = model.predict(padded)
        print("ðŸ”¹ Prediction:", prediction)

        return {"prediction": prediction.tolist()}

    except Exception as e:
        print(" Internal Server Error:", str(e))
        return {"error": str(e)}
